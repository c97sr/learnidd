---
title: "Influenza Forecasting Solutions"
author: "Steven Riley, Caroline Walters, Ada Yan"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{forecasting_ans}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=5, fig.height=3)
```




## Objectives

After successfully completing this practical, you should be able to:

* Understand the objectives of forecasting.
* Understand how accuracy in forecasting is assessed.
* Be able to use a linear model to make a forecast (appropriate R code provided).
* Be able to use a simple mechanistic model to make a forecast (appropriate R code provided).
* Be able to use a historical null model as a benchmark.

## Format

**Timing**:  We have sufficient time to meet our objectives, however, we expect people to progress at different rates depending on their familiarity with the concepts and their experience with R.  Extension questions are included for anyone who finishes early, or for you to look over outside of this practical.  At various points in time we will come together as a group to review answers and to discuss issues that arise. 

**Approach**: This practical is designed to be completed individually, however discussion with others is encouraged.  The initial questions are quite specific and are designed to help you familiarise yourself with the material. The questions become more and more open-ended as you progress through the practical.

**Using R**:  We will continue using R in this practical session.  You will be provided with the R code for the practical.

To access the help files for the functions used in the practical, type `help("function_name")` (e.g. `help("extract_incidence")`).
To look at the source code for the functions, type the function name by itself (e.g. `extract_incidence`).

## Background to the Task

You will be using WHO data showing weekly influenza-like illness incidence from many different countries.  For a specific country you will be shown the weekly incidence for a period of 52 weeks.  Using a small subset of this data, you will be predicting the incidence for the coming weeks and comparing your predictions with the actual data. You will investigate different models.

## 1. Initial investigation of the data

First, load the data set.
Plot the data on influenza-like illness in Israel for all years.
```{r}
library(learnidd)
```

```{r}
data("fluIliCountryData")
plot_incidence_all(fluIliCountryData, "ISR")
```

**Qu. 1.1**: How many weekly incidence reports do you have in your dataset?

**Ans. 1.1**: Looks like 52 weeks per year, 7 years: 364 weekly reports

**Qu. 1.2**: What month(s) and years(s) does the dataset contain?

**Ans. 1.2**: 

The full set contains data from January 2010 to the present.
The plot shows the incidence for the 2010 - 2016 flu seasons (inclusive).
The plot has been shifted by 26 weeks such that the peak is in the middle of the plot.
Week 26 is July so data points are for 52 consecutive weeks from July - July.

**Qu. 1.3**: What differences do you see across the years?

**Ans. 1.3**: 

* Timing of peak of curve (peak time)
* Height of peak (peak incidence)
* shape of the curves - 2010 curve has steeper gradient than the 2011 curve

Now plot the weekly incidence data for Israel in 2016.

```{r plot incidence}
incidence_data <- extract_incidence(fluIliCountryData, 
                    country = "ISR", 
                    year = 2016)

plot_incidence(incidence_data, log_scale = FALSE)
```

We define that an epidemic is occurring if the incidence for a given week exceeds a threshold.
For the purposes of this practical, we choose this threshold to be 250 individuals.

The onset time of the epidemic is then the first week during which the incidence exceeds the threshold.

The duration of the epidemic is the time between when the epidemic first exceeds the threshold (onset time) up to the final week that the incidence exceeds the threshold.

**Qu. 1.4**: for each year (2010-2016), by visual inspection of the plot, identify the onset time, peak time, peak incidence and duration of the epidemic.  
Record your results in a table.

**Ans. 1.4** Answers are approximate.

```{r, echo = FALSE}
year <- seq(2010, 2016, by = 1)
onset_time <- c(18, 20, 20, 23, 20, 21, 21)
end_time <- c(37, 41, 38, 41, 40, 38, 36)
peak_time <- c(28, 35, 31, 34, 32, 30, 27)
peak_incidence <- c(4900, 1450, 3700, 2700, 2450, 3600, 2250)
duration <- end_time - onset_time

data.frame(year, onset_time, peak_time, peak_incidence, duration)

```

If you would like to get some accurate numbers, you can run code such as

```{r}
threshold <- 250
# onset time
above_threshold <- which(incidence_data$incidence > threshold)
as.character(incidence_data[above_threshold[1], "time_name"])
# peak timing
as.character(incidence_data[which.max(incidence_data$incidence), "time_name"])
# peak height
max(incidence_data$incidence, na.rm = TRUE)
# duration of epidemic 
sum(incidence_data$incidence > threshold, na.rm = TRUE)
```

We will now use our knowledge of the real situation to explore different models for prediction.


## 2. Linear Regression on Linear Incidence

Assume that we are part way through the time period covered by the data, at week 49. We have the weekly incidence for week 49 and the four preceding weeks, so 5 data points in total. We can fit a linear model to our data points to predict future weekly incidence values.

First we fit the linear model.
Run the code
```{r}
linear_regression_output <- linear_regression(incidence_data,
                              current_week = 49,
                              n_weeks_prior = 4,
                              log_transform = FALSE)
```
```{r eval = TRUE}
linear_regression_output
```

**Qu. 2.1** What are the meanings of the values for `intercept` and `gradient`?

**Ans. 2.1** Imagine joining our predicted dots together with a curve: this would be a straight line. 
t is the gradient of the straight line. This is how much our predicted incidence increases between successive weeks.
intercept is the value of the straight line at time 0. It has no real world meaning in this model.

**Extension Qu. 2.1a** Look at the source code of the function `linear_regression`.
Find the line in the source code which performs the linear regression.
Can you figure out what the function does? (Google may help.)

**Extension Ans. 2.1a**

```{r}
linear_regression
```
`linear_regression_output <- lm(incidence ~ t, data = incidence_data)` performs linear regression.
It uses the dataset `incidence_data`, and performs linear regression of the variable `incidence` versus the variable `t`.

Now we use the fitted model to predict the incidence for future weeks.
Run the code

```{r}
prediction_df <- extract_predicted_points(linear_regression_output, 
                                         incidence_data,
                                         weeks_ahead = 8,
                                         log_transform = FALSE)
```
```{r eval = TRUE}
plot_incidence(prediction_df)
```

**Qu. 2.2** What do you think the black, red and blue points represent on this chart?

**Ans. 2.2** 

* Black: real data points
* Red: Real data points that we use to make a prediction from
* Blue: predictions of weekly incidence

**Qu. 2.3** At what times (if any) do you think the model gives a good prediction?  In qualitative terms, does prediction accuracy change over time? If so, how?

**Ans. 2.3** 
No \'right\' answer to this question, but some observations: 

* Viewing points in isolation, Week 2017-04 appears to be the closest prediction. However, in the wider context, at that point the epidemic incidence is decreeasing each week and the model predicts increase.
* Overall, the linear regression model underpredicts incidence at early times and overpredicts incidence at late times.
* The linear regression model does not capture the exponential growth during the early stages of the epidemic.

### How can we assess if a prediction is accurate?

From the previous question you may have developed a personal view on when the model is \'good\', however we want to have a formal way of defining 'good'.  We can consider if a prediction point lies within 25% either way of the actual value.  We can do this for all prediction points and then consider the proportion of points that are within this tolerance.

Consider the previous example of making predictions at week 49, using data from the previous 4 weeks.  We want to make predictions about the coming 8 weeks.
Extract the predicted and observed incidence by running

```{r eval = TRUE}
extract_subset_prediction(prediction_df)
```

**Qu. 2.4** Calculate the accuracy interval for each data point: lower bound is 0.75 times the observed incidence; upper bound is 1.25 times the observed incidence. Record the information in a table. Now look to see if the prediction value lies with the accuracy interval range. Calculate the proportion of points where this holds.
*Note: the poor qualitative fit by linear regression on linear incidence suggests that the proportion of "accurate" predictions will be low.*
*Do not be alarmed if you get a very low proportion of "accurate" predictions -- this exercise will make more sense when we compare the proportion of "accurate" predictions using this model to the proportion of "accurate" predictions in the next section.*

```{r eval = TRUE}
subset_prediction <- extract_subset_prediction(prediction_df)
lower_bound <- 0.75*subset_prediction$incidence
upper_bound <- 1.25*subset_prediction$incidence
prediction_bounds <- cbind(subset_prediction, lower_bound, upper_bound)
prediction_bounds

calc_prediction_accuracy(prediction_bounds)
```

**Qu. 2.5** What might be causes of error in the prediction?

**Ans. 2.5** The linear regression model does not capture the exponential growth during the early stages of the epidemic, or the decline in incidence as susceptibles are depleted.
This suggests that linear regression on a linear scale is not an appropriate method for making forecasts.


## 3. Linear Regression on Log Incidence

We will now repeat what we have just done but will perform linear regression on the log transform of the data.

Run the code
```{r}
linear_regression_output <- linear_regression(incidence_data,
                              current_week = 49,
                              n_weeks_prior = 4,
                              log_transform = TRUE)

prediction_df <- extract_predicted_points(linear_regression_output,
                                         incidence_data,
                                         weeks_ahead = 8,
                                         log_transform = TRUE)
```
```{r eval = TRUE}
plot_incidence(prediction_df)
```

**Qu. 3.1** How does the prediction with the log transform differ qualitatively from the prediction without the log transform?

**Ans. 3.1**
The prediction with the log transform predicts an exponential increase in cases, whereas the prediction without the log transform predicts a linear increase in cases.
As a result, the prediction with the log transform appears to predict the first few weeks ahead better than without the transform.*

**Qu. 3.2** When, if at any time, do you think the model gives a good prediction?  Does accuracy change over time? If so, how?

**Ans. 3.2**
Weeks 50, 51, and 52 look like good predictions, but no \`right\` answer. 
Accuracy gets worse as the model predicts further ahead, because the model predicts a continued exponential increase rather than a decline in the epidemic.

**Qu. 3.3** Compare the accuracy of this prediction with the log transform to the prediction in the previous section.
```{r eval = TRUE}
calc_prediction_accuracy(prediction_df)
```

**Ans. 3.3**
The accuracy has increased.

Now repeat this predicting process but using data from more weeks prior.  In the code to produce `linear_regression_output`, change `n_weeks_prior` to 5, 6, 7 and 8.  Keep a copy of the results and compare them to your results using data from 4 weeks prior.
*Note: we have stored information in for our plot in an object called `prediction_df`. When you change the value of `n_weeks_prior` and re-run the code, this will overwrite `prediction_df`.  This is not a problem, however if you would like to save the information for different plots then you must create new objects, e.g. `prediction_df2`.*

To speed up the process of calculating the accuracy, you can run
```{r eval = FALSE}
calc_prediction_accuracy(prediction_df)
```

**Qu. 3.4** For a starting week of week 49, what is the value of `n_weeks_prior` that gives the best prediction?  For how many weeks is the prediction accurate?

```{r}

for(i in 4:8){
  linear_regression_output <- linear_regression(incidence_data = incidence_data,
                              current_week = 49,
                              n_weeks_prior = i,
                              log_transform = TRUE)
  
  prediction_df <- extract_predicted_points(linear_regression_output,
                                         incidence_data,
                                         weeks_ahead = 8,
                                         log_transform = TRUE)
  accuracy <- calc_prediction_accuracy(prediction_df)
  print(accuracy)
}

```
**Ans. 3.4**
Intermediate values of `n_weeks_prior` gie a better prediction than very large or small values.
Values of `n_weeks_prior` of 5, 6, or 7 give an accuracy of 0.5. 
The prediction is accurate for 4 out of the 8 weeks.

**Qu. 3.5** What might be causes of error in the prediction?

**Ans. 3.5**
Linear regression on a log scale predicts a continued exponential increase rather than a decline in the epidemic due to the depletion of susceptibles.
This suggests that linear regression on a log scale is not an appropriate method for predicting the peak timing, height or duration of an epidemic, although it does very well in the early stages of the epidemic.

If too few data points are used, a small amount of error in each data point can change our estimate of the gradient drastically, decreasing the accuracy of our prediction.
On the other hand, if too many data points are used, we may be using data from vary early stages of the epidemic where the growth is not exponential.
For example, there is a roughly constant background level of influenza infection throughout the year, such as due to importation of cases from elsewhere.
If we use data points from this background level, the data will not be captured by an exponential curve, and so the model is not suited to modelling this data.
Also, during the very early stages of the epidemic, the spread of cases may be limited to local spread, such that infectious individuals don't have the opportunity to contact the whole population; this may cause growth to be slower than exponential.

##########################################################################

## 4. SEIR Model

SEIR (Susceptible-Exposed-Infected-Recovered) models are often used to model influenza.  You will now look at a prediction using an SEIR model.
The model equations are

$$\frac{dS}{dt} = -\frac{\beta SI}{N}$$
$$\frac{dE}{dt} = \frac{\beta SI}{N} - \frac{E}{\tau_E}$$
$$\frac{dI}{dt} = \frac{E}{\tau_E} - \frac{I}{\tau_I}$$
$$\frac{dR}{dt} = \frac{I}{\tau_I}$$

The below table contains a description of model parameters.

```{r, echo = FALSE}
params_df <- data.frame(Parameter = c("$R_0 = \\beta \\tau_I$",
                                      "$\\tau_E$",
                                      "$\\tau_I$",
                                      "$N$",
                                      "$I_0$",
                                      "$r$"),
                        Description = c("Basic reproduction number",
                                        "Latent period",
                                        "Infectious period",
                                        "Population size",
                                        "Initial number of infectious individuals",
                                        "Proportion of cases which are reported"),
                                      Value = c("varied",
                                                "1.6 day$^{-1}$",
                                                "1 day$^{-1}$",
                                                "$8.5 \\times 10^6$",
                                                "100",
                                                "0.006"))
knitr::kable(params_df)
```

The equation for the cumulative incidence is
$$\frac{dC}{dt} = \frac{E}{\tau_E}$$;
that is, the cumulative incidence is the number of individuals which have ever entered the infectious class by a given time.
The incidence during a given week can then be obtained by subtracting the cumulative incidence of that week from the cumulative incidence in the previous week.

To make a prediction using the SEIR model, we fit the model parameters to the incidence data which we are using to predict.
In this practical, we will focus on fitting the basic reproduction number $R_0$, and assume that all other parameter values are known (see table above).

We fit the model to the data by maximising the likelihood of observing the data given model parameters.
We will assume that the observed incidence is Poisson distributed with respect to the actual incidence, with an additional correction for the proportion of cases which are reported.

First, we will plot the log likelihood for a range of $R_0$, to get a sense of where the maximum might be.

```{r}
current_week <- 49
starting_week <- 37 # our guess for the start time of the epidemic. We assume that
# the epidemic starts with 100 infectious individuals at this time.
R_0_min <- 1
R_0_max <- 5
likelihood_profile_output <- likelihood_profile_seir(incidence_data, current_week, starting_week, R_0_min, R_0_max)
```
```{r eval = TRUE, fig.height = 3, fig.width = 3}
plot_likelihood_profile(likelihood_profile_output)
```

**Qu. 4.1** From looking at the likelihood profile, what is the most likely value of $R_0$?
Is this a reasonable value of $R_0$?

**Ans. 4.1**
Approximately $R_0$ = 1.3. Reasonable for flu.

When we fit the SEIR model to the data, we will need to choose reasonable bounds of $R_0$ to search over.
Plotting the likelihood profile helps us choose these bounds.
The bounds should include the peak of the log likelihood which we have seen visually.  
Ideally it should not include very flat regions of parameter space where the fitting algorithm will have trouble finding the maximum (in this case, very high values of $R_0$).

By visually inspecting the plot we decide that we will search between $R_0 = 1$ and $R_0 = 2$.
Run the code
```{r}
R_0_min <- 1
R_0_max <- 2
R_0 <- fit_seir(incidence_data, current_week, starting_week, R_0_min, R_0_max)
```
```{r eval = TRUE}
R_0
```

**Qu. 4.2** What is the value of $R_0$ that maximises the likelihood?
How does this compare to the value found visually?

**Ans. 4.2**
See above for value -- it is close to what we found visually, which is a good sign that the maximisation algorithm has worked.

**Extension qu. 4.2a** Look at the source code of `fit_seir`.
Identify the function which maximises the likelihood function.

**Extension ans. 4.2a**
```{r}
fit_seir
```

The `optimise` function maximises the likelihood function.

**Extension qu. 4.2b** Look at the source code of `solve_seir_model`.
Match the lines in the functions to the differential equations.

**Extension ans. 4.2b**

```{r}
solve_seir_model
```

Lines 5-7 encode $\frac{dS}{dt}$, $\frac{dE}{dt}$ and $\frac{dI}{dt}$.
Line 8 encodes $\frac{dC}{dt}$.
Because $S + E + I + R = N$ is constant, we don't need to write the equation for $\frac{dR}{dt}$.

Now predict the future incidence using the fitted model.
Run the code
```{r}
# predict using found value of R_0
prediction_df <- extract_predicted_points_seir(R_0, incidence_data, 
                                           current_week,
                                           starting_week, 
                                           weeks_ahead = 8)
```
```{r eval = TRUE}
# plot prediction
plot_incidence(prediction_df)
calc_prediction_accuracy(prediction_df)
```
Save a copy of your plot in your Word file.

**Qu. 4.3** What features of the incidence curve are captured by the SEIR model prediction which were not captured by the linear regression prediction?

**Ans. 4.3**
Epidemic growth and decline; the peak.

**Qu. 4.4** Which weeks, if any, does the model give a good prediction for?
**Ans. 4.4**
All of them as our accuracy proportion is 1

**Qu. 4.5** Compare the prediction accuracy of the SEIR and linear regression models.

**Ans. 4.5**
SEIR is more accurate for predicting the peak timing, height and duration of the epidemic.

**Qu. 4.6** Because the SEIR model can reproduce the shape of the epidemic curve, we can assess how well it captures the peak timing, peak incidence and duration of the epidemic.
Perform this assessment.

**Ans. 4.6**
From visual inspection, the SEIR model correctly predicts peak timing. Good estimate of peak incidence.  The duration is underestimated (the incidence drops too quickly).

To get some numbers:

```{r}
prediction_df <- extract_predicted_points_seir(R_0, incidence_data, 
                                           current_week = 37,
                                           starting_week, 
                                           weeks_ahead = 20)
threshold <- 250
# observed peak timing
as.character(prediction_df[which.max(prediction_df$incidence), "time_name"])
# predicted peak timing
as.character(prediction_df[which.max(prediction_df$prediction), "time_name"])
# observed peak height
max(prediction_df$incidence, na.rm = TRUE)
# predicted peak height
max(prediction_df$prediction, na.rm = TRUE)
# observed duration of epidemic 
sum(prediction_df$incidence > threshold, na.rm = TRUE)
# predicted duration of epidemic 
sum(prediction_df$prediction > threshold, na.rm = TRUE)
```

**Qu. 4.7** Change the current week to take values between 45 and 5 (in the next year).  How does the accuracy of the prediction change, in terms of the proportion of points within the threshold, and the peak timing and height?

```{r}

for(i in c(45:52, 1:5)){
  # re-fit R_0 using new number of weeks
  R_0 <- fit_seir(incidence_data, current_week = i, starting_week, R_0_min, R_0_max)
  # predict using fitted R_0
  prediction_df <- extract_predicted_points_seir(R_0, incidence_data, 
                                             current_week = i,
                                             starting_week, 
                                             weeks_ahead = 8)

  plot_incidence(prediction_df)
  accuracy <- calc_prediction_accuracy(prediction_df)
  print(accuracy)
}

```

```{r, echo = FALSE}

wrapper <- function(current_week){
  # re-fit R_0 using new number of weeks
  R_0 <- fit_seir(incidence_data, current_week, starting_week, R_0_min, R_0_max)
  # predict using fitted R_0
  prediction_df <- extract_predicted_points_seir(R_0, incidence_data, 
                                             current_week,
                                             starting_week, 
                                             weeks_ahead = 8)

  g <- plot_incidence(prediction_df)
  g
}
g <- lapply(c(45, 49, 52, 3, 5), wrapper)
```

Some example plots:

Week 45:

```{r, echo = FALSE}
g[[1]]
```

The model is fitting a value of $R_0$ that is too large, so the peak height is too high and the peak time is too early.

Week 49:

```{r, echo = FALSE}
g[[2]]
```

The model is doing well.

Week 52:

```{r, echo = FALSE}
g[[3]]
```

The model is doing well.

Week 3:

```{r, echo = FALSE}
g[[4]]
```

The model predicts correctly that we have observed the peak, so the peak height and timing are perfect.
The indicence is dropping too quickly.

Week 5:

```{r, echo = FALSE}
g[[5]]
```

Once again, the incidence is dropping too quickly.

**Extension qu. 4.7a** How sensitive is the prediction to our guess of when the epidemic started?


**Extension ans. 4.7a**
What happens if we think the epidemic starts at week 36 instead of week 37?

```{r}

current_week <- 49
starting_week <- 36
R_0 <- fit_seir(incidence_data, current_week, starting_week, R_0_min, R_0_max)
prediction_df <- extract_predicted_points_seir(R_0, incidence_data, 
                                           current_week,
                                           starting_week, 
                                           weeks_ahead = 8)

plot_incidence(prediction_df)

```


The model now underestimates the peak height, although the peak timing is the same.
If we think the epidemic started earlier than it does, tthe epidemic has to grow more slowly to fit the same data, so we will estimate a lower value of $R_0$ and thus a lower peak height.
Thus, the prediction is quite sensitive to our guess of when the epidemic started.
We could improve our prediction method by fitting $R_0$ and the starting week of the epidemic simultaneously to data.

**Qu. 4.8** What might be causes of error in the prediction?

Some possible causes of error:

1. Misspecification of fixed model parameters

The SEIR model has many parameters, but we only fit one parameter $R_0$.
We fixed the other parameters according to values in the literature.
The parameter values may change from year to year; for example, the latent and infectious period may be different for different influenza strains, and the proportion of reported cases may change from year to year.
Thus, the values from the literature may not be the best-fitting values for the current season.
For example, towards the end of the epidemic, the predicted incidence seems to be dropping too quickly.
The drop in the incidence is driven by recovery of infectious invididuals; thus, if the predicted incidence seems to be dropping too quickly, our estimate of the recovery rate may be too high, i.e. our estimate of the recovery time may be too short.
To minimise the chance of misspecifying model parameters, we could fit more than one parameter at once, although that runs the risk of overfitting if we don't have enough data.

2. Model misspecification

Things we have not taken into account in this model include

* Population heterogeneity
* Stochasticity in the infection process
* Waning of immunity
* Co-circulating influenza strains etc.

We don't know which of these factors might influence the predictions.

## Extension work

If you have completed all of the tasks, please ask one of the course demonstrators for extension work.